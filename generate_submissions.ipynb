{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87197d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fc3788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from pathlib import Path\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf0c3f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"data/results_test/*.json\"\n",
    "results = glob.glob(results_path)\n",
    "results = [Path(p) for p in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6824bc73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/results_test/hermes-8b.json'),\n",
       " PosixPath('data/results_test/hermes-8b-rag-reorder.json'),\n",
       " PosixPath('data/results_test/hermes-3b-lora-reorder.json'),\n",
       " PosixPath('data/results_test/hermes-3b-lora-rag-reorder.json'),\n",
       " PosixPath('data/results_test/openai-4o-mini.json'),\n",
       " PosixPath('data/results_test/openai-4o-mini-rag.json'),\n",
       " PosixPath('data/results_test/openai-4o-mini-rag-reorder.json'),\n",
       " PosixPath('data/results_test/hermes-8b-reorder.json'),\n",
       " PosixPath('data/results_test/hermes-3b.json'),\n",
       " PosixPath('data/results_test/hermes-3b-lora.json'),\n",
       " PosixPath('data/results_test/hermes-3b-rag-reorder.json'),\n",
       " PosixPath('data/results_test/openai-4o-mini-reorder.json'),\n",
       " PosixPath('data/results_test/hermes-3b-reorder.json')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542aa7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hermes-8b',\n",
       " 'hermes-8b-rag-reorder',\n",
       " 'hermes-3b-lora-reorder',\n",
       " 'hermes-3b-lora-rag-reorder',\n",
       " 'openai-4o-mini',\n",
       " 'openai-4o-mini-rag',\n",
       " 'openai-4o-mini-rag-reorder',\n",
       " 'hermes-8b-reorder',\n",
       " 'hermes-3b',\n",
       " 'hermes-3b-lora',\n",
       " 'hermes-3b-rag-reorder',\n",
       " 'openai-4o-mini-reorder',\n",
       " 'hermes-3b-reorder']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_ids = {\n",
    "    \"T621\": \"binary_tag_based_relations\",\n",
    "    \"T622\": \"ternary_tag_based_relations\",\n",
    "    \"T623\": \"ternary_mention_based_relations\",\n",
    "}\n",
    "run_ids = [str(p.name).split(\".\")[0] for p in results]\n",
    "system_id = \"CLEANR\"\n",
    "team_id = \"ToGS\"\n",
    "run_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a6c56be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chevron\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "07278b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "staging_dir = Path(\"./staging\")\n",
    "for task_id, task_key in task_ids.items():\n",
    "    for run_id, result_path in zip(run_ids, results):\n",
    "        run_id_simples = run_id.replace(\"-\", \"\")\n",
    "\n",
    "        identifier = f\"{team_id}_{task_id}_{run_id_simples}_{system_id}\"\n",
    "        identifier_dir = staging_dir / identifier\n",
    "        if not identifier_dir.exists():\n",
    "            os.mkdir(identifier_dir)\n",
    "        desc_data = \"\"\n",
    "        with open(\"description.md\", \"r\") as f:\n",
    "            desc_data = f.read(-1)\n",
    "        flags = []\n",
    "        if \"rag\" in run_id:\n",
    "            flags.append(\"RAG\")\n",
    "        if \"reorder\" in run_id:\n",
    "            flags.append(\"Reordered\")\n",
    "        if \"lora\" in run_id:\n",
    "            flags.append(\"Finetuned using LoRA\")\n",
    "        rendered_desc = chevron.render(\n",
    "            desc_data,\n",
    "            {\n",
    "                \"task_id\": task_id,\n",
    "                \"run_id\": run_id,\n",
    "                \"system_id\": system_id,\n",
    "                \"team_id\": team_id,\n",
    "                \"flags\": flags,\n",
    "            },\n",
    "        )\n",
    "        desc_file = identifier_dir / f\"{identifier}.md\"\n",
    "        out_file = identifier_dir / f\"{identifier}.json\"\n",
    "        with open(desc_file, \"w\") as f:\n",
    "            f.write(rendered_desc)\n",
    "        run_data: dict[str, dict[str, any]] = None\n",
    "        with open(result_path, \"r\") as rf:\n",
    "            run_data = json.load(rf)\n",
    "        stratified_res = {}\n",
    "        for k, res in run_data.items():\n",
    "            stratified_res[k] = {task_key: res[task_key]}\n",
    "        with open(out_file, \"w\") as rf:\n",
    "            json.dump(stratified_res, rf)\n",
    "\n",
    "        zip_path = staging_dir / f\"{identifier}.zip\"\n",
    "        zf = ZipFile(zip_path, \"w\")\n",
    "        zf.write(desc_file, f\"{identifier}.md\")\n",
    "        zf.write(out_file, f\"{identifier}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cb0833e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# GutBrain IE Challenge @ CLEF 2025: CLEANR\\n\\n`Benedikt Kantz, Peter Walder, Stefan Lengauer, Tobias Schreck`\\n* Team ID: ToGS\\n* TaskID: T623\\n* RunID: hermes-3b-reorder\\n* Run Flags\\n  - Reordered\\n* GitHub: https://github.com/Dakantz/CLEANR\\n## Our appraoch\\n* Use a RAG approach to prompt a LM to return the relations\\n  - fetch similar articles from VectorDB to give good examples (if the run ID contains `rag`)\\n  - reorder the RAG data to improve the handling of the model, i.e. put Gold annotations before Silver (if the run ID contains `reorder`)\\n  - finetune the Hermes model on the test data (if the run ID contains `lora`)\\n* We also use different models:\\n  - `NousResearch/Hermes-3-Llama-3.2-3B` + a finetuned LoRA-version\\n  - `NousResearch/Hermes-3-Llama-3.1-8B`\\n  - `gpt-4o-mini-2024-07-18`\\n\\n\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rendered_desc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
