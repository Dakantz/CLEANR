{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87197d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54fc3788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import json\n",
    "from constrerl.annotator import load_test, load_train, Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27f0da60",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_path = Path(\"data/onto\")\n",
    "result_file_types=[\"union\",\"intersection\"]\n",
    "for rft in result_file_types:\n",
    "    ontug_files = onto_path.glob(f\"ontug-{rft}*.json\")\n",
    "    combined_articles: dict[str, Article] = {}\n",
    "    for ontug_file in ontug_files:\n",
    "        articles = load_train(ontug_file)\n",
    "        for id, article in articles.items():\n",
    "            if id not in combined_articles:\n",
    "                combined_articles[id] = article\n",
    "            else:\n",
    "                existing_article = combined_articles[id].model_dump()\n",
    "                new_article = article.model_dump()\n",
    "                for key, value in article.model_dump().items():\n",
    "                    if key not in existing_article or existing_article[key] is None:\n",
    "                        existing_article[key] = new_article[key]\n",
    "                combined_articles[id] = Article.model_validate(existing_article)\n",
    "\n",
    "    with open(onto_path / f\"ontug_test_{rft}_results.json\", \"w\") as f:\n",
    "        json.dump(\n",
    "            {id: article.model_dump() for id, article in combined_articles.items()},\n",
    "            f,\n",
    "            indent=2,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf0c3f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"data/onto/ontug_test_*.json\"\n",
    "results = glob.glob(results_path)\n",
    "results = [Path(p) for p in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6824bc73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/onto/ontug_test_union_results.json'),\n",
       " PosixPath('data/onto/ontug_test_intersection_results.json')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "542aa7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['union', 'intersection']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_ids = {\n",
    "    \"T621\": \"binary_tag_based_relations\",\n",
    "    \"T622\": \"ternary_tag_based_relations\",\n",
    "    \"T623\": \"ternary_mention_based_relations\",\n",
    "}\n",
    "run_ids = [str(p.name).split(\"_\")[2] for p in results]\n",
    "system_id = \"ElectraCLEANR\"\n",
    "team_id = \"ONTUG\"\n",
    "run_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a6c56be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chevron\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07278b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "staging_dir = Path(\"./staging_ontug\")\n",
    "for task_id, task_key in task_ids.items():\n",
    "    for run_id, result_path in zip(run_ids, results):\n",
    "        run_id_simples = run_id.replace(\"-\", \"\")\n",
    "\n",
    "        identifier = f\"{team_id}_{task_id}_{run_id_simples}_{system_id}\"\n",
    "        identifier_dir = staging_dir / identifier\n",
    "        if not identifier_dir.exists():\n",
    "            os.mkdir(identifier_dir)\n",
    "        desc_data = \"\"\n",
    "        with open(\"description_ontug.md\", \"r\") as f:\n",
    "            desc_data = f.read(-1)\n",
    "        flags = [\"lora\", \"rag\", \"reorder\"]\n",
    "        if \"rag\" in run_id:\n",
    "            flags.append(\"RAG\")\n",
    "        if \"reorder\" in run_id:\n",
    "            flags.append(\"Reordered\")\n",
    "        if \"lora\" in run_id:\n",
    "            flags.append(\"Finetuned using LoRA\")\n",
    "        rendered_desc = chevron.render(\n",
    "            desc_data,\n",
    "            {\n",
    "                \"task_id\": task_id,\n",
    "                \"run_id\": run_id,\n",
    "                \"system_id\": system_id,\n",
    "                \"team_id\": team_id,\n",
    "                \"flags\": flags,\n",
    "            },\n",
    "        )\n",
    "        desc_file = identifier_dir / f\"{identifier}.meta\"\n",
    "        out_file = identifier_dir / f\"{identifier}.json\"\n",
    "        with open(desc_file, \"w\") as f:\n",
    "            f.write(rendered_desc)\n",
    "        run_data: dict[str, dict[str, any]] = None\n",
    "        with open(result_path, \"r\") as rf:\n",
    "            run_data = json.load(rf)\n",
    "        stratified_res = {}\n",
    "        for k, res in run_data.items():\n",
    "            stratified_res[k] = {task_key: res[task_key]}\n",
    "        with open(out_file, \"w\") as rf:\n",
    "            json.dump(stratified_res, rf)\n",
    "\n",
    "        # zip_path = staging_dir / f\"{identifier}.zip\"\n",
    "        # zf = ZipFile(zip_path, \"w\")\n",
    "        # zf.write(desc_file, f\"{identifier}.md\")\n",
    "        # zf.write(out_file, f\"{identifier}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cb0833e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# GutBrain IE Challenge @ CLEF 2025: ElectraCLEANR\\n\\n* Team ID: ONTUG\\n* TaskID: T623\\n* RunID: intersection\\n* Run Flags\\n  - lora\\n  - rag\\n  - reorder\\n* GitHub: https://github.com/Dakantz/CLEANR\\n## Our appraoch\\n* Use a RAG approach to prompt a LM to return the relations\\n  - fetch similar articles from VectorDB to give good examples (if the run ID contains `rag`)\\n  - reorder the RAG data to improve the handling of the model, i.e. put Gold annotations before Silver (if the run ID contains `reorder`)\\n  - finetune the Hermes model on the train data combinations, with text+annotation pairs (if the run ID contains `lora`)\\n* We also use different models:\\n  - `NousResearch/Hermes-3-Llama-3.2-3B` + a finetuned LoRA-version\\n  - `NousResearch/Hermes-3-Llama-3.1-8B`\\n  - `gpt-4o-mini-2024-07-18`\\n* Merged with the Graphwise team, strategy based on run ID (either intersection or union):\\n  - Type of training applied. Finetuning `microsoft/BiomedNLP-BiomedELECTRA-base-uncased-abstract` on task T61 after that the model is further finetuned on task T623.\\n  - Pre-processing methods. The one provided in the baseline repo\\n  - Training data used. The one provided by the competition organizers plus data annotated by the gliner model provided as baseline.\\n  - Relevant details of the run. The model is finetuned on the training data for 100 epochs, train_batch_size 2 , gradient_accumulation_steps 2 , learning_rate 5e-5 , max_grad_norm 1.0 , warmup_ratio 0.06 '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rendered_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2859d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
