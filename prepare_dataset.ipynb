{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constrerl.annotator import (\n",
    "    Annotator,\n",
    "    load_train,\n",
    "    Article\n",
    ")\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = pl.Path(\"data/annotations/train\")\n",
    "test_data_dir = pl.Path(\"data/annotations/dev\")\n",
    "train_data_files = list(train_data_dir.glob(\"*.json\"))\n",
    "test_data_files = list(test_data_dir.glob(\"*.json\"))\n",
    "\n",
    "train_data: dict[str, Article] = {}\n",
    "for file in train_data_files:\n",
    "    train_data.update(load_train(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1567"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator = Annotator()\n",
    "failed_articles: list[tuple[Article, Exception]] = []\n",
    "\n",
    "def export_train_date(train_data: dict[str, Article], path: pl.Path):\n",
    "    train_data_chats = []\n",
    "    for article in train_data.values():\n",
    "        try:\n",
    "            chat = Annotator.prompt_and_respone(article)\n",
    "            train_data_chats.append({\"article\": article.model_dump(), \"messages\": chat})\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            failed_articles.append(\n",
    "                (\n",
    "                    article,\n",
    "                    e,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(train_data_chats, f)\n",
    "    # jsonl dump\n",
    "    with open(path.with_suffix(\".jsonl\"), \"w\") as f:\n",
    "        for chat in train_data_chats:\n",
    "            #with system prompt\n",
    "            del chat[\"article\"]\n",
    "            chat[\"messages\"] = annotator.example_messages + chat[\"messages\"]\n",
    "            f.write(json.dumps(chat) + \"\\n\")\n",
    "\n",
    "\n",
    "for train_data_file in train_data_files+test_data_files:\n",
    "    collection_name = train_data_file.name.split(\".\")[0].split(\"_\")[-1]\n",
    "    export_train_date(\n",
    "        load_train(train_data_file),\n",
    "        pl.Path(\n",
    "            *train_data_file.parts[:-3], f\"train_data_chats_{collection_name}.json\"\n",
    "        ),\n",
    "    )\n",
    "export_train_date(train_data, pl.Path(\"data/annotations/train_data_chats.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_relations_all = {}\n",
    "for article, err in failed_articles:\n",
    "    missing_relations: dict[str, dict[str, str]] = {}\n",
    "    for e in err.errors():\n",
    "        index = e[\"loc\"][1]\n",
    "        spo_id = e[\"loc\"][-1]\n",
    "        if index not in missing_relations:\n",
    "            missing_relations[index] = {\n",
    "                \"subject_label\": None,\n",
    "                \"predicate\": None,\n",
    "                \"object_label\": None,\n",
    "            }\n",
    "        missing_relations[index][spo_id] = e[\"input\"]\n",
    "    for index, missing_relation in missing_relations.items():\n",
    "        names = missing_relation.values()\n",
    "        spo= \"->\".join(names)\n",
    "        if spo not in missing_relations_all:\n",
    "            missing_relations_all[ \"->\".join(names)] = []\n",
    "        missing_relations_all[spo].append(article.metadata.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "relations_missing = []\n",
    "for spo, articles in missing_relations_all.items():\n",
    "    s, p, o = spo.split(\"->\")\n",
    "    relations_missing.append(   \n",
    "            {\n",
    "                \"heads\": [s],\n",
    "                \"tails\": [o],\n",
    "                \"predicate\": [p],\n",
    "            }\n",
    "    )\n",
    "print(json.dumps(relations_missing, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"missing_relations.txt\", \"w\") as f:\n",
    "    for spo, titles in missing_relations_all.items():\n",
    "        f.write(f\"{spo}:\\n\")\n",
    "        for title in titles:\n",
    "            f.write(f\"\\t{title}\\n\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"err.log\", \"w\") as f:\n",
    "    for article, e in failed_articles:\n",
    "        f.write(f\"{article.model_dump_json(indent=2)}\\n {e}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
