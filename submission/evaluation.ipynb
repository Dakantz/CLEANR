{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constrerl.evaluate import (\n",
    "    eval_submission_6_1_NER,\n",
    "    eval_submission_6_3_ternary_tag_RE,\n",
    "    eval_submission_6_4_ternary_mention_RE,\n",
    "    eval_submission_6_2_binary_tag_RE\n",
    ")\n",
    "from constrerl.erl_schema import convert_to_output, Article\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections.abc import Callable, Awaitable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"../data/results_dev\"\n",
    "ground_truth_file = \"../data/annotations/dev/dev.json\"\n",
    "\n",
    "results_dir = Path(results_dir)\n",
    "ner_result_dir = Path(\"../data/results_ner_dev\")\n",
    "ground_truth_file = Path(ground_truth_file)\n",
    "\n",
    "\n",
    "with open(ground_truth_file) as f:\n",
    "    ground_truth = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Removed 458 duplicated entities from predictions ===\n",
      "=== Removed 111 overlapping entities ===\n",
      "=== Removed 335 duplicated entities from predictions ===\n",
      "=== Removed 88 overlapping entities ===\n",
      "=== Removed 458 duplicated entities from predictions ===\n",
      "=== Removed 111 overlapping entities ===\n",
      "=== Removed 384 duplicated entities from predictions ===\n",
      "=== Removed 72 overlapping entities ===\n",
      "=== Removed 231 duplicated entities from predictions ===\n",
      "=== Removed 82 overlapping entities ===\n",
      "=== Removed 231 duplicated entities from predictions ===\n",
      "=== Removed 82 overlapping entities ===\n",
      "=== Removed 327 duplicated binary tag-based relations from predictions ===\n",
      "=== Removed 1059 duplicated binary tag-based relations from predictions ===\n",
      "=== Removed 1105 duplicated binary tag-based relations from predictions ===\n",
      "=== Removed 447 duplicated binary tag-based relations from predictions ===\n",
      "=== Removed 368 duplicated binary tag-based relations from predictions ===\n",
      "=== Removed 304 duplicated binary tag-based relations from predictions ===\n",
      "=== Removed 134 duplicated binary tag-based relations from predictions ===\n",
      "=== Removed 1105 duplicated binary tag-based relations from predictions ===\n",
      "=== Removed 934 duplicated binary tag-based relations from predictions ===\n",
      "=== Removed 304 duplicated binary tag-based relations from predictions ===\n",
      "=== Removed 1403 duplicated binary tag-based relations from predictions ===\n",
      "=== Removed 327 duplicated ternary tag-based relations from predictions ===\n",
      "=== Removed 1058 duplicated ternary tag-based relations from predictions ===\n",
      "=== Removed 1105 duplicated ternary tag-based relations from predictions ===\n",
      "=== Removed 447 duplicated ternary tag-based relations from predictions ===\n",
      "=== Removed 368 duplicated ternary tag-based relations from predictions ===\n",
      "=== Removed 304 duplicated ternary tag-based relations from predictions ===\n",
      "=== Removed 134 duplicated ternary tag-based relations from predictions ===\n",
      "=== Removed 1105 duplicated ternary tag-based relations from predictions ===\n",
      "=== Removed 934 duplicated ternary tag-based relations from predictions ===\n",
      "=== Removed 304 duplicated ternary tag-based relations from predictions ===\n",
      "=== Removed 1403 duplicated ternary tag-based relations from predictions ===\n",
      "=== Removed 159 duplicated ternary mention-based relations from predictions ===\n",
      "=== Removed 780 duplicated ternary mention-based relations from predictions ===\n",
      "=== Removed 906 duplicated ternary mention-based relations from predictions ===\n",
      "=== Removed 303 duplicated ternary mention-based relations from predictions ===\n",
      "=== Removed 82 duplicated ternary mention-based relations from predictions ===\n",
      "=== Removed 64 duplicated ternary mention-based relations from predictions ===\n",
      "=== Removed 8 duplicated ternary mention-based relations from predictions ===\n",
      "=== Removed 906 duplicated ternary mention-based relations from predictions ===\n",
      "=== Removed 658 duplicated ternary mention-based relations from predictions ===\n",
      "=== Removed 64 duplicated ternary mention-based relations from predictions ===\n",
      "=== Removed 960 duplicated ternary mention-based relations from predictions ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:48: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:49: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:50: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:51: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:52: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:48: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:49: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:50: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:51: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:52: SyntaxWarning: invalid escape sequence '\\c'\n",
      "/tmp/ipykernel_225504/3196633549.py:48: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  \"RAG\": \"\\checkmark\" if \"rag\" in result_file.name else \"$\\\\times$\",\n",
      "/tmp/ipykernel_225504/3196633549.py:49: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  \"LoRA\": \"\\checkmark\" if \"lora\" in result_file.name else \"$\\\\times$\",\n",
      "/tmp/ipykernel_225504/3196633549.py:50: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  \"Reorder\": \"\\checkmark\" if \"reorder\" in result_file.name else \"$\\\\times$\",\n",
      "/tmp/ipykernel_225504/3196633549.py:51: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  \"Low Tokens\": \"\\checkmark\" if \"low-tokens\" in result_file.name else \"$\\\\times$\",\n",
      "/tmp/ipykernel_225504/3196633549.py:52: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  \"Entity Labels\": \"\\checkmark\" if \"entity-labels\" in result_file.name else \"$\\\\times$\",\n"
     ]
    }
   ],
   "source": [
    "eval_results: list[dict] = []\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def scoring_to_dict(\n",
    "    f: str | Path, eval_f: Callable[[str | Path, dict], tuple[float]]\n",
    ") -> dict:\n",
    "    precision, recall, f1, micro_precision, micro_recall, micro_f1 = eval_f(\n",
    "        f, ground_truth\n",
    "    )\n",
    "    return {\n",
    "        \"$P$\": precision,\n",
    "        \"$R$\": recall,\n",
    "        \"$F_1$\": f1,\n",
    "        \"$P_{micro}$\": micro_precision,\n",
    "        \"$R_{micro}$\": micro_recall,\n",
    "        \"$F_{1,micro}$\": micro_f1,\n",
    "    }\n",
    "\n",
    "\n",
    "def scoring_to_df(\n",
    "    eval_f: Callable[[str | Path, dict], tuple[float]], res_dir=results_dir\n",
    ") -> pd.DataFrame:\n",
    "    eval_results: list[dict] = []\n",
    "    for result_file in res_dir.glob(\"*.json\"):\n",
    "        result_file = Path(result_file)\n",
    "        eval_result = scoring_to_dict(result_file, eval_f)\n",
    "        model_name = (\n",
    "            \" \".join(result_file.name.rstrip(\".json\").split(\"-\")[:2])\n",
    "            if \"openai\" not in result_file.name\n",
    "            else \" \".join(result_file.name.rstrip(\".json\").split(\"-\")[:3])\n",
    "        )\n",
    "        # capitalize the first letter of the name\n",
    "        model_name = \" \".join(\n",
    "            [\n",
    "                word.capitalize() if i == 0 else word\n",
    "                for i, word in enumerate(model_name.split(\" \"))\n",
    "            ]\n",
    "        )\n",
    "        model_name = re.sub(r\"(\\d)b\", \"\\\\1B\", model_name)\n",
    "        splits = model_name.split(\" \")\n",
    "        if len(splits) > 2:\n",
    "            model_name = splits[0] + \" \" + \"-\".join(splits[1:])\n",
    "\n",
    "        result_dict = {\n",
    "            \"Model\": model_name,\n",
    "            \"RAG\": \"\\checkmark\" if \"rag\" in result_file.name else \"$\\\\times$\",\n",
    "            \"LoRA\": \"\\checkmark\" if \"lora\" in result_file.name else \"$\\\\times$\",\n",
    "            \"Reorder\": \"\\checkmark\" if \"reorder\" in result_file.name else \"$\\\\times$\",\n",
    "            \"Low Tokens\": \"\\checkmark\" if \"low-tokens\" in result_file.name else \"$\\\\times$\",\n",
    "            \"Entity Labels\": \"\\checkmark\" if \"entity-labels\" in result_file.name else \"$\\\\times$\",\n",
    "        }\n",
    "        result_dict.update(eval_result)\n",
    "        # result_dict.update({f\"6_2_2_{k}\": v for k, v in ternary_tag_score.items()})\n",
    "        # result_dict.update({f\"6_2_3_{k}\": v for k, v in ternary_mention_score.items()})\n",
    "        eval_results.append(result_dict)\n",
    "    eval_df = pd.DataFrame(eval_results)\n",
    "    if \"$F_{1,micro}$\" in eval_df.columns:\n",
    "        eval_df = eval_df.sort_values(\"$F_{1,micro}$\")\n",
    "    return eval_df\n",
    "\n",
    "\n",
    "task_6_1_1_df = scoring_to_df(eval_submission_6_1_NER, res_dir=ner_result_dir)\n",
    "task_6_2_1_df = scoring_to_df(eval_submission_6_2_binary_tag_RE)\n",
    "task_6_2_2_df = scoring_to_df(eval_submission_6_3_ternary_tag_RE)\n",
    "task_6_2_3_df = scoring_to_df(eval_submission_6_4_ternary_mention_RE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_6_2_1_df.to_latex(\n",
    "    \"report/task_6_1_1.tex\",\n",
    "    float_format=\"%.2f\",\n",
    "    caption=\"Dev Set Result for Task 6.1.1 (NER) for various models and approaches.\",\n",
    "    label=\"tab:task:6_1_1:more\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_6_2_1_df.to_latex(\n",
    "    \"report/task_6_2_1.tex\",\n",
    "    float_format=\"%.2f\",\n",
    "    caption=\"Further Dev Set Result for Task 6.2.1 for various models and approaches.\",\n",
    "    label=\"tab:task:6_2_1:more\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_6_2_2_df.to_latex(\n",
    "    \"report/task_6_2_2.tex\",\n",
    "    float_format=\"%.2f\",\n",
    "    caption=\"Further Dev Set Result for Task 6.2.2 for various models and approaches.\",\n",
    "    label=\"tab:task:6_2_2:more\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_6_2_3_df.to_latex(\n",
    "    \"report/task_6_2_3.tex\",\n",
    "    float_format=\"%.2f\",\n",
    "    caption=\"Further Dev Set Result for Task 6.2.3 for various models and approaches.\",\n",
    "    label=\"tab:task:6_2_3:more\",\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
